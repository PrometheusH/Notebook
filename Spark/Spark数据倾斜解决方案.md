# Spark数据倾斜解决方案

首先数据倾斜的解决分为**聚合型数据倾斜**和**join型数据倾斜**，各自有不同的场景，对应不同的解决方案。

<u>数据倾斜的原理</u>

在进行shuffle的时候，必须将各个节点上相同的key拉取到某个节点上的一个task来处理。

<u>如何判断出现了数据倾斜？</u>

从Spark Web UI上看当前这个stage各个task分配的数据量和处理的时间，有的处理几秒钟，有的处理几分钟就已经发生倾斜了。

<u>可能导致数据倾斜的算子</u>

distinct、groupByKey、reduceByKey、aggregateByKey、join、cogroup、repartition

**场景一：**

> 一个RDD在进行xxxByKey时发生了倾斜

**方法：**两阶段聚合

**解决：**第一次聚合，将每条记录打上n以内的随机数作为前缀，进行聚合，第二次，将随机数去掉，进行聚合。



**场景二：**

> 当两个RDD进行join时，如果一个RDD的数据量比较小（几百M或一两G），而另一个RDD中的数据是倾斜的。

**方法：**将reduce join转化为map join

**解决：**将较小数据量的RDD进行广播，在大数据量RDD的map算子中从广播变量中查找符合当前记录的记录进行连接。



**场景三：**

> 当两个RDD都比较大时（大于10G），其中一个RDD的数据是倾斜的，而另一个是均匀分布的，而且导致倾斜的key个数在10以上。

**方法：**使用随机前缀扩容RDD进行join

**解决：**将倾斜的RDD的每条数据的key都打上一个n以内的随机前缀，对另一个正常的RDD进行扩容，每条数据都扩容成n条，扩容出来的数据每一条都依次打着0~n的前缀，将两个RDD进行join。

**缺点：**因为一个RDD膨胀了n倍，会占用过多的内存。



**场景四：**

> 当两个RDD都比较大时（大于10G），其中一个RDD的数据是倾斜的，而另一个是均匀分布的，而且导致倾斜的key个数在10个以下。

**方法：**采样倾斜key并分拆join操作

**解决：**通过sample算子采样一份样本出来，统计一下每个key的数量，计算出数据量最大的key是哪几个。然后将这几个key从原RDD中过滤出来，形成一个单独的RDD，给此RDD的每条记录都打上n以内的随机数作为前缀，将另一个均匀RDD中含有这些key的记录过滤出来，对每条记录膨胀n倍，打上0~n的前缀，形成另一个独立的RDD。将这两个RDD进行join的结果与剩余两个RDD的结果进行union就是最终结果。



模板：

**场景一：**

> 

**方法：**

**解决：**



