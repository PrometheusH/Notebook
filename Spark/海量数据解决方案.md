# 海量数据解决方案

**给定a、b两个文件，各存放50亿个url，每个url占64个字节，内存限制是4G，找出a、b文件中相同的url。**

首先50\*10的8次方\*64/1024/1024约为320G>4G

> 遍历文件a，对每个url取hash(url)%1000，然后根据取得的值，将url分别存储到1000个小文件（记为a0、a1，...，a999）。每个文件约为300M。
>
> 遍历文件b，对每个url取hash(url)%1000，然后根据取得的值，将url分别存储到1000个小文件（记为b0、b1，...，b999）。
>
> 将a0中url取出，放到hash_set中，遍历b0中的url，如果该url在hash_set中，则将其放入相同文件中即可。

如果数据发生了倾斜，导致一个文件中的数据量大于了4G，怎么办？



**有10个文件，每个文件1G，每个文件的每一行存放的都是用户的query，每个文件的query都可能重复，要求按照query的频度排序。**

query数据的特点是重复的次数比较多

> 方法一：一边读入，一边在hash_map中进行计数，最后对次数进行排序即可。



**搜素引擎会通过日志文件把用户每次检索所使用的的所有检索串都记录下来，每个查询串的长度为1~255字节。假设目前有一千万条记录，这些查询串的重复度比较高，虽然总数是一千万，但是如果去除重复的，不超过300万个，一个查询串的重复度越高，说明查询它的用户越多，也就越热门。请统计最热门的10个查询串，要求使用内存不能超过1G。(1)请你描述这个问题的解决思路，（2）请给出主要的处理流程，算法，以及算法的复杂度。**

> 因为255\*3000000/1024/1024约为729.5G>1G，所以不能将所有记录的统计次数存储在内存中。4\*255\*1024=1G，所以每次内存中只能存4048个字符串及其对应的数量。这里有300万个字符串，3000000/4048=741，故至少要分成741个文件，然后依次读取每个文件，计算每个字符串出现的次数，将出现次数前十的记录及其次数，写入一个文件，一共是7410个字符串及其次数。建立一个hash_map只存10个值，每次读入一条记录，将最小次数的记录替换，最终得到10条记录。







归纳：

方法一：逐条读入，此时去重后的记录的大小不能大于内存的大小

方法二：逐条读入后，hash分文件，此时每个记录的总条数不能大于内存的大小

一：统计出现次数最多的N个数据

每条数据的大小

数据量多少

去重后大约有多少

内存限制多大

二：去重

